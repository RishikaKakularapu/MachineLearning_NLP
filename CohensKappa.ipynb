{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a67f3f9-c6f8-4789-a715-7bca261b56f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Agreement: 0.745\n",
      "Expected Agreement: 0.5077079999999999\n",
      "Cohen's Kappa: 0.48201473921981264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load the two CSV files into separate data frames\n",
    "file1 = pd.read_csv('C:/Users/rishi/OneDrive/Desktop/Cohens_kappa/cohens_task1_file1.csv')\n",
    "file2 = pd.read_csv('C:/Users/rishi/OneDrive/Desktop/Cohens_kappa/cohens_task1_file2.csv')\n",
    "\n",
    "# Check if the two data frames have the same number of rows\n",
    "assert file1.shape[0] == file2.shape[0], \"The two CSV files have different numbers of rows!\"\n",
    "\n",
    "# Calculate the observed agreement between the two annotators\n",
    "observed_agreement = sum(file1['Task 1'] == file2['Task 1']) / len(file1)\n",
    "\n",
    "# Create a contingency table that shows the frequency of each combination of labels\n",
    "table = pd.crosstab(file1['Task 1'], file2['Task 1'], rownames=['Annotator 1'], colnames=['Annotator 2'])\n",
    "\n",
    "# Calculate the expected agreement between the two annotators\n",
    "total = table.sum().sum()\n",
    "marginals = np.outer(table.sum(axis=1), table.sum(axis=0)) / total\n",
    "expected_agreement = (marginals.diagonal().sum() / total)\n",
    "\n",
    "# Calculate Cohen's kappa\n",
    "kappa = cohen_kappa_score(file1['Task 1'], file2['Task 1'])\n",
    "\n",
    "# Print the results\n",
    "print(\"Observed Agreement:\",observed_agreement)\n",
    "print(\"Expected Agreement:\",expected_agreement)\n",
    "print(\"Cohen's Kappa:\",kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b001ab2-9179-4e28-b158-1b26af408572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Agreement: 0.463\n",
      "Expected Agreement: 0.1648916183450718\n",
      "Cohen's Kappa: 0.35691087287672807\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load the two CSV files into separate data frames\n",
    "file1 = pd.read_csv('C:/Users/rishi/OneDrive/Desktop/Cohens_kappa/cohens_task2A_file1.csv')\n",
    "file2 = pd.read_csv('C:/Users/rishi/OneDrive/Desktop/Cohens_kappa/cohens_task2A_file2.csv')\n",
    "\n",
    "# Check if the two data frames have the same number of rows\n",
    "assert file1.shape[0] == file2.shape[0], \"The two CSV files have different numbers of rows!\"\n",
    "\n",
    "# Calculate the observed agreement between the two annotators\n",
    "observed_agreement = sum(file1['Task 2A'] == file2['Task 2A']) / len(file1)\n",
    "\n",
    "# Create a contingency table that shows the frequency of each combination of labels\n",
    "table = pd.crosstab(file1['Task 2A'], file2['Task 2A'], rownames=['Annotator 1'], colnames=['Annotator 2'])\n",
    "\n",
    "# Calculate the expected agreement between the two annotators\n",
    "total = table.sum().sum()\n",
    "marginals = np.outer(table.sum(axis=1), table.sum(axis=0)) / total\n",
    "expected_agreement = (marginals.diagonal().sum() / total)\n",
    "file1['Task 2A'] = file1['Task 2A'].astype(str)\n",
    "file2['Task 2A'] = file2['Task 2A'].astype(str)\n",
    "\n",
    "# Calculate Cohen's kappa\n",
    "kappa = cohen_kappa_score(file1['Task 2A'], file2['Task 2A'])\n",
    "\n",
    "# Print the results\n",
    "print(\"Observed Agreement:\",observed_agreement)\n",
    "print(\"Expected Agreement:\",expected_agreement)\n",
    "print(\"Cohen's Kappa:\",kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47781a6-6fd6-4a7d-8886-d62cb431c751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
